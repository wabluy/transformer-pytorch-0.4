import os
from collections import Counter

import regex
import numpy as np
from torch.utils.data import Dataset

MAXLEN = 10
MINCNT = 20
PAD = 0
UNK = 1
BOS = 2
EOS = 3


def make_vocab(corpora_filepath, vocab_filename):
    """Construct vocab from file src_path to file vocab_path.

    Arguments:
        corpora_filepath: English or German file path.
        vocab_filename: vocab file name.
    Returns:
        An int. Number of vocab.
    """
    with open(corpora_filepath, "r", encoding="utf-8") as fr:
        text = fr.read()
        text = regex.sub("[^\s\p{Latin}']", "", text)
    vocabs = text.split()
    vocab2num = Counter(vocabs)
    if not os.path.exists("preprocessed"):
        os.mkdir("preprocessed")
    with open(os.path.join("preprocessed", vocab_filename), "w", encoding="utf-8") as fw:
        fw.write("{}\t1000000000\n{}\t1000000000\n{}\t1000000000\n{}\t1000000000\n".format(
            "<PAD>", "<UNK>", "<BOS>", "<EOS>"))
        for vocab, num in vocab2num.most_common():
            fw.write("{}\t{}\n".format(vocab, num))
    return len(vocab2num) + 4


def load_vocab(language="en"):
    """Load vocab file generated by func make_vocab() and Return two python dict."""
    if language == "en":
        filepath = os.path.join("preprocessed", "en.vocab.tsv")
    elif language == "de":
        filepath = os.path.join("preprocessed", "de.vocab.tsv")
    with open(filepath, "r", encoding="utf-8") as fr:
        vocabs = [line.split()[0] for line in fr.readlines() if int(line.split()[1]) >= MINCNT]
    vocab2idx = {vocab: idx for idx, vocab in enumerate(vocabs)}
    idx2vocab = {idx: vocab for idx, vocab in enumerate(vocabs)}
    return vocab2idx, idx2vocab


def load_data(mode="train"):
    """Load train or test data.

    Arguments:
        mode: Str. "train" or "test".
    Returns:
        (X, Y): Numpy array of shape=(sent_num, maxlen).
        Both X and Y are sentences with <EOS> as the last word.
    """
    if mode == "train":
        src_filepath = os.path.join("corpora", "train.tags.de-en.de")
        tgt_filepath = os.path.join("corpora", "train.tags.de-en.en")
        with open(src_filepath, "r", encoding="utf-8") as fr:
            de_sents = [regex.sub("[^\s\p{Latin}']", "", line) for line in fr.readlines() if line and line[0] != "<"]
        with open(tgt_filepath, "r", encoding="utf-8") as fr:
            en_sents = [regex.sub("[^\s\p{Latin}']", "", line) for line in fr.readlines() if line and line[0] != "<"]
    elif mode == "test":
        src_filepath = os.path.join("corpora", "IWSLT16.TED.tst2014.de-en.de.xml")
        tgt_filepath = os.path.join("corpora", "IWSLT16.TED.tst2014.de-en.en.xml")

        def _refine(line):
            line = regex.sub("<[^>]+>", "", line)
            line = regex.sub("[^\s\p{Latin}']", "", line)
            return line.strip()
        with open(src_filepath, "r", encoding="utf-8") as fr:
            de_sents = [_refine(line) for line in fr.readlines() if line and line[0:4] == "<seg"]
        with open(tgt_filepath, "r", encoding="utf-8") as fr:
            en_sents = [_refine(line) for line in fr.readlines() if line and line[0:4] == "<seg"]

    de2idx, _ = load_vocab(language="de")
    en2idx, _ = load_vocab(language="en")
    x_list = []
    y_list = []
    for de_sent, en_sent in zip(de_sents, en_sents):
        x = [de2idx.get(vocab, UNK) for vocab in (de_sent + " <EOS>").split()]
        y = [en2idx.get(vocab, UNK) for vocab in (en_sent + " <EOS>").split()]
        if max(len(x), len(y)) <= MAXLEN:
            x_list.append(x)
            y_list.append(y)
    X = np.zeros((len(x_list), MAXLEN), dtype=np.int64)
    Y = np.zeros((len(y_list), MAXLEN), dtype=np.int64)
    for i, (x, y) in enumerate(zip(x_list, y_list)):
        X[i] = np.lib.pad(x, [0, MAXLEN - len(x)], "constant", constant_values=(PAD, PAD))
        Y[i] = np.lib.pad(y, [0, MAXLEN - len(y)], "constant", constant_values=(PAD, PAD))

    return X, Y


class CustomDataset(Dataset):
    def __init__(self, mode="train"):
        self.X, self.Y = load_data(mode)

    def __getitem__(self, index):
        return self.X[index], self.Y[index]

    def __len__(self):
        return self.X.shape[0]


if __name__ == "__main__":
    make_vocab("corpora\\train.tags.de-en.de", "de.vocab.tsv")
    make_vocab("corpora\\train.tags.de-en.en", "en.vocab.tsv")
